{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Implementation of GRU on the time-series dataset"
      ],
      "metadata": {
        "id": "fhoxpkJ1gbdq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guvyaHFmgZnR"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVvDLuNNg4mH",
        "outputId": "1eb6b6c7-ed10-4792-fca0-29e4d3e19a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load test features and labels\n",
        "X_test = np.load('/content/drive/MyDrive/Dataset of ai/rolling_window_sequnces_1.npy')  # Replace with actual file path\n",
        "metadata_test = pd.read_csv(\"/content/drive/MyDrive/Dataset of ai/sequence_metadata_with_RUL (1).csv\")  # Replace with actual file path\n",
        "y_test = metadata_test[\"RUL\"].values\n",
        "print(\"Test feature shape:\", X_test.shape)\n",
        "print(\"Test target shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSSLrUWMghwK",
        "outputId": "4d917877-921f-445f-f101-afed085c7675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test feature shape: (17631, 30, 66)\n",
            "Test target shape: (17631,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation sets (assuming no separate train set given)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_test, y_test, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "HEOfA_Pcg_T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define GRU model creation function\n",
        "def create_gru_model(input_shape, units=64, learning_rate=0.001, dropout_rate=0.2):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(units, input_shape=input_shape))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "QOH8_k6mhGK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = create_gru_model(input_shape=(X_train.shape[1], X_train.shape[2]), units=64, learning_rate=0.001, dropout_rate=0.2)\n",
        "\n",
        "# Callbacks for early stopping\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "]"
      ],
      "metadata": {
        "id": "_91ZFbffhGIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39267d9-5f1e-4971-b2bd-57d50bc11f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbFxorIIhZlK",
        "outputId": "ba028563-5c3c-4f28-e989-4b9ad30f4bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 8016.9370 - mae: 78.4196 - val_loss: 6364.6011 - val_mae: 68.1893\n",
            "Epoch 2/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6005.4126 - mae: 65.5869 - val_loss: 5068.2461 - val_mae: 59.2524\n",
            "Epoch 3/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 4760.8330 - mae: 57.0085 - val_loss: 4050.9717 - val_mae: 51.8954\n",
            "Epoch 4/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 3870.2195 - mae: 50.6451 - val_loss: 3244.0984 - val_mae: 45.6268\n",
            "Epoch 5/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 3100.3445 - mae: 44.6026 - val_loss: 2596.6348 - val_mae: 40.3759\n",
            "Epoch 6/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 2464.6675 - mae: 39.3324 - val_loss: 2023.4224 - val_mae: 35.3280\n",
            "Epoch 7/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 1938.1782 - mae: 34.6324 - val_loss: 1572.5248 - val_mae: 30.8407\n",
            "Epoch 8/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 1497.7661 - mae: 30.2013 - val_loss: 1145.4210 - val_mae: 26.1367\n",
            "Epoch 9/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 1070.3334 - mae: 25.3718 - val_loss: 844.4556 - val_mae: 22.6320\n",
            "Epoch 10/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 816.1119 - mae: 22.4651 - val_loss: 640.8523 - val_mae: 19.7953\n",
            "Epoch 11/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 634.9361 - mae: 19.9728 - val_loss: 527.5374 - val_mae: 18.4170\n",
            "Epoch 12/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 518.4886 - mae: 18.2375 - val_loss: 424.6094 - val_mae: 16.7703\n",
            "Epoch 13/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 458.1158 - mae: 17.3202 - val_loss: 340.4811 - val_mae: 14.8701\n",
            "Epoch 14/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 385.3238 - mae: 15.9318 - val_loss: 312.6893 - val_mae: 14.6371\n",
            "Epoch 15/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 331.3000 - mae: 14.8144 - val_loss: 283.7874 - val_mae: 13.8278\n",
            "Epoch 16/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 307.6099 - mae: 14.1455 - val_loss: 256.7068 - val_mae: 12.9904\n",
            "Epoch 17/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 263.4701 - mae: 13.0858 - val_loss: 202.4693 - val_mae: 11.3915\n",
            "Epoch 18/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 236.1926 - mae: 12.2394 - val_loss: 186.4539 - val_mae: 10.9390\n",
            "Epoch 19/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 225.0926 - mae: 11.8100 - val_loss: 174.4171 - val_mae: 10.3647\n",
            "Epoch 20/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 206.9167 - mae: 11.2500 - val_loss: 189.9315 - val_mae: 10.6611\n",
            "Epoch 21/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 206.2438 - mae: 11.1865 - val_loss: 152.1687 - val_mae: 9.4378\n",
            "Epoch 22/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 203.0110 - mae: 10.9220 - val_loss: 154.9678 - val_mae: 9.4672\n",
            "Epoch 23/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 179.9640 - mae: 10.2534 - val_loss: 146.1883 - val_mae: 9.1180\n",
            "Epoch 24/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 175.9688 - mae: 10.1155 - val_loss: 136.9998 - val_mae: 8.6736\n",
            "Epoch 25/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 175.6897 - mae: 10.0432 - val_loss: 166.4974 - val_mae: 9.4201\n",
            "Epoch 26/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 164.0272 - mae: 9.7327 - val_loss: 133.1760 - val_mae: 8.6307\n",
            "Epoch 27/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 159.8125 - mae: 9.6643 - val_loss: 122.2945 - val_mae: 8.1396\n",
            "Epoch 28/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 155.9381 - mae: 9.4632 - val_loss: 120.8157 - val_mae: 8.1736\n",
            "Epoch 29/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 148.8133 - mae: 9.1763 - val_loss: 122.4269 - val_mae: 7.9508\n",
            "Epoch 30/30\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 144.8365 - mae: 9.1580 - val_loss: 126.4978 - val_mae: 8.3411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate on validation set\n",
        "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f'Validation MSE: {val_loss:.4f}, MAE: {val_mae:.4f}')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "# Calculate test MSE\n",
        "test_mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Test MSE: {test_mse:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGciZ0tGheJI",
        "outputId": "8ab50d24-4c4c-432c-c5ee-f03f7b775d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 120.8157, MAE: 8.1736\n",
            "\u001b[1m551/551\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "Test MSE: 106.5865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Dataset of ai/best_gru_model.keras\")"
      ],
      "metadata": {
        "id": "WRw1IqR-lj8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
